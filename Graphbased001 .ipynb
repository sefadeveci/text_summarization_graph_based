{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk \n",
    "from nltk.corpus import stopwords \n",
    "from nltk.tokenize import word_tokenize, sent_tokenize \n",
    "import numpy as np\n",
    "import math\n",
    "from rouge import Rouge \n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Metinleri direkt olarak txt üzerinden okuyorum ancak sizin için daha anlaşılır olması adına direkt olarak texti kopyaladım.\n",
    "text=\"\"\"Dollar gains on Greenspan speech\n",
    "\n",
    "The dollar has hit its highest level against the euro in almost three months after the Federal Reserve head said the US trade deficit is set to stabilise.\n",
    "\n",
    "And Alan Greenspan highlighted the US government's willingness to curb spending and rising household savings as factors which may help to reduce it. In late trading in New York, the dollar reached $1.2871 against the euro, from $1.2974 on Thursday. Market concerns about the deficit has hit the greenback in recent months. On Friday, Federal Reserve chairman Mr Greenspan's speech in London ahead of the meeting of G7 finance ministers sent the dollar higher after it had earlier tumbled on the back of worse-than-expected US jobs data. \"I think the chairman's taking a much more sanguine view on the current account deficit than he's taken for some time,\" said Robert Sinche, head of currency strategy at Bank of America in New York. \"He's taking a longer-term view, laying out a set of conditions under which the current account deficit can improve this year and next.\"\n",
    "\n",
    "Worries about the deficit concerns about China do, however, remain. China's currency remains pegged to the dollar and the US currency's sharp falls in recent months have therefore made Chinese export prices highly competitive. But calls for a shift in Beijing's policy have fallen on deaf ears, despite recent comments in a major Chinese newspaper that the \"time is ripe\" for a loosening of the peg. The G7 meeting is thought unlikely to produce any meaningful movement in Chinese policy. In the meantime, the US Federal Reserve's decision on 2 February to boost interest rates by a quarter of a point - the sixth such move in as many months - has opened up a differential with European rates. The half-point window, some believe, could be enough to keep US assets looking more attractive, and could help prop up the dollar. The recent falls have partly been the result of big budget deficits, as well as the US's yawning current account gap, both of which need to be funded by the buying of US bonds and assets by foreign firms and governments. The White House will announce its budget on Monday, and many commentators believe the deficit will remain at close to half a trillion dollars.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenize_sent = sent_tokenize(text) \n",
    "#Noktalama işaretlerinin kaldırılması işlemleri \n",
    "import re\n",
    "for i in range(0,len(tokenize_sent)):\n",
    "        tokenize_sent[i]=re.sub(r'[^\\w\\s]','',tokenize_sent[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "adj_matrix= np.zeros((len(tokenize_sent),len(tokenize_sent))) #Cümle sayısına göre \n",
    "sent_rank = np.random.rand(len(tokenize_sent)) #Cümle değerleri için tuttuğum değişken\n",
    "\n",
    "#Stopword'lerin kaldırılması\n",
    "stop = stopwords.words('english')\n",
    "process_sent=list()\n",
    "    \n",
    "for i in range(0,len(tokenize_sent)):\n",
    "    if i not in stop:\n",
    "        process_sent.append(tokenize_sent[i].split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq=dict()\n",
    "copy_sent=process_sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Stemming işlemi \n",
    "from nltk.stem import PorterStemmer \n",
    "ps= PorterStemmer()\n",
    "for sentence_in_running,i in enumerate(process_sent):\n",
    "    for word_in_running,j in enumerate(i):\n",
    "        copy_sent[sentence_in_running][word_in_running]=ps.stem(j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Kelime sıklığı\n",
    "for sentence in copy_sent:\n",
    "    for word in sentence:\n",
    "        if word in freq:\n",
    "            freq[word]=freq[word]+1\n",
    "        else :\n",
    "            freq[word]=1\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Matris için kenarların belirlenmesi işlemleri, Distortion\n",
    "\n",
    "def calculate_different(i,j):\n",
    "    find_diff=0\n",
    "    point=0\n",
    "    sent_i=copy_sent[i]\n",
    "    sent_j=copy_sent[j]\n",
    "    for word in sent_i:\n",
    "        test_diff=sent_j.count(word)  #2. cümlede şuan için işlenen kelimenin geçme sıklığı\n",
    "        point=(freq[word]-test_diff)+point #Toplam sıklıktan 2. cümle sıklığını düşürerek cümleler arası puanlama\n",
    "        if(test_diff==0): # Eğer kelime benzer değilse farklılık +1 \n",
    "            find_diff=find_diff+1 \n",
    "    for word in sent_j: # 2. cümlede bulunup, 1. cümlede olmayan kelimeleri, puana ekliyorum aynı zamanda farklılık değişkenini artırıyyorum\n",
    "        if word not in sent_i:\n",
    "            point=point+freq[word]\n",
    "            find_diff=find_diff+1\n",
    "    if(find_diff==0):\n",
    "        find_diff=1\n",
    "    different=(point/float(find_diff))*2 # Terimlerin sıklıkları üzerinden hesaplanan puan ve farklı kelime sayısına göre bir kenar değeri elde ediyorum\n",
    "    return different"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Yukarıda bulunan fonksiyonu metinde geçen her kelime için tekrarlama\n",
    "for i in range(0,len(tokenize_sent)):\n",
    "    for j in range(i+1,len(tokenize_sent)):\n",
    "        adj_matrix[i,j] = adj_matrix[j,i] = calculate_different(i,j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "cümleler={}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Her cümle için kendi içinde bulunan kelimelerin sıklığını almak istiyorum. Buna göre Node değerlerini belirlemek için\n",
    "for i in range(len(copy_sent)):\n",
    "    cümleler[i]=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0, len(copy_sent)):\n",
    "    for j in range(0,len(copy_sent[i])):\n",
    "        cümleler[i]=cümleler[i]+freq[copy_sent[i][j]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 458,\n",
       " 1: 204,\n",
       " 2: 212,\n",
       " 3: 202,\n",
       " 4: 398,\n",
       " 5: 334,\n",
       " 6: 210,\n",
       " 7: 110,\n",
       " 8: 282,\n",
       " 9: 344,\n",
       " 10: 138,\n",
       " 11: 430,\n",
       " 12: 240,\n",
       " 13: 510,\n",
       " 14: 280}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cümleler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ranking işlemi. Node her cümleyi temsil ediyor. Her cümlenin puanını hesaplarken aynı zamanda diğer cümlelerde bulunan \n",
    "#farklılık değerlerini de göz önünde bulunduruyorum. Karesini alma işlemini eşitlik durumlarını en aza indirmek için yaptım\n",
    "def calculate_weight(sent_rank,adjacency,shp,cümleler):\n",
    "    sent_rank = np.array(sent_rank)\n",
    "    for node1 in range(0,shp[0]):\n",
    "        sent_rank[node1] = 0\n",
    "        for node2 in range(0,shp[0]):\n",
    "            sent_rank[node1] = (adj_matrix[node1,node2]*cümleler[node1])**2+sent_rank[node1]\n",
    "            \n",
    "    return sent_rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_rank = calculate_weight(sent_rank,adj_matrix,adj_matrix.shape,cümleler)\n",
    "sentences_rank=(sent_rank).argsort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "And Alan Greenspan highlighted the US governments willingness to curb spending and rising household savings as factors which may help to reduce it\n",
      "In late trading in New York the dollar reached 12871 against the euro from 12974 on Thursday\n",
      "Market concerns about the deficit has hit the greenback in recent months\n",
      "Hes taking a longerterm view laying out a set of conditions under which the current account deficit can improve this year and next\n",
      "The G7 meeting is thought unlikely to produce any meaningful movement in Chinese policy\n",
      "The halfpoint window some believe could be enough to keep US assets looking more attractive and could help prop up the dollar\n"
     ]
    }
   ],
   "source": [
    "#Yukarıda her cümle için tek bir değer oluşturdum ve bunları sıraladım. Aşağıda artık sıralanan cümleler arasında en yüksek değerli\n",
    "#Cümleleri seçme ve yazdırma işlemlerini gerçekleştirdim\n",
    "summarization_sorted=np.sort(sentences_rank[1:7])\n",
    "for i in range(0,len(summarization_sorted)):\n",
    "    print(tokenize_sent[summarization_sorted[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'rouge-1': {'f': 0.5999999950133196,\n",
       "   'p': 0.6326530612244898,\n",
       "   'r': 0.5705521472392638},\n",
       "  'rouge-2': {'f': 0.4480519430654411,\n",
       "   'p': 0.4726027397260274,\n",
       "   'r': 0.42592592592592593},\n",
       "  'rouge-l': {'f': 0.5585585535589644,\n",
       "   'p': 0.5535714285714286,\n",
       "   'r': 0.5636363636363636}}]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Rouge-Score\n",
    "hypothesis1=\"\"\"And Alan Greenspan highlighted the US government's willingness to curb spending and rising household savings as factors which may help to reduce it.In late trading in New York, the dollar reached $1.2871 against the euro, from $1.2974 on Thursday.Market concerns about the deficit has hit the greenback in recent months.On Friday, Federal Reserve chairman Mr Greenspan's speech in London ahead of the meeting of G7 finance ministers sent the dollar higher after it had earlier tumbled on the back of worse-than-expected US jobs data.\"I think the chairman's taking a much more sanguine view on the current account deficit than he's taken for some time, said Robert Sinche, head of currency strategy at Bank of America in New York.\"He's taking a longer-term view, laying out a set of conditions under which the current account deficit can improve this year and next.\"\"\"\n",
    "reference1=\"\"\"\"The dollar has hit its highest level against the euro in almost three months after the Federal Reserve head said the US trade deficit is set to stabilise.China's currency remains pegged to the dollar and the US currency's sharp falls in recent months have therefore made Chinese export prices highly competitive.Market concerns about the deficit has hit the greenback in recent months.\"I think the chairman's taking a much more sanguine view on the current account deficit than he's taken for some time,\" said Robert Sinche, head of currency strategy at Bank of America in New York.The recent falls have partly been the result of big budget deficits, as well as the US's yawning current account gap, both of which need to be funded by the buying of US bonds and assets by foreign firms and governments.\"He's taking a longer-term view, laying out a set of conditions under which the current account deficit can improve this year and next.\"\"\"\n",
    "rouge = Rouge()\n",
    "scores = rouge.get_scores(hypothesis1, reference1)\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
