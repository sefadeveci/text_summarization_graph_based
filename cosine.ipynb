{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk \n",
    "from nltk.corpus import stopwords \n",
    "from nltk.tokenize import word_tokenize, sent_tokenize \n",
    "import numpy as np\n",
    "import math\n",
    "from rouge import Rouge \n",
    "import string\n",
    "import re\n",
    "from nltk.stem import PorterStemmer \n",
    "from rouge import Rouge \n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def metinoku(i):\n",
    "    no=str(i)\n",
    "    a=\"ent/ham/\"\n",
    "    b=\".txt\"\n",
    "    return a+no+b\n",
    "def özetal(i):\n",
    "    no=str(i)\n",
    "    a=\"ent/özet/\"\n",
    "    b=\".txt\"\n",
    "    ada=a+no+b\n",
    "    txt=open(ada,\"r\")\n",
    "    f=txt.read()\n",
    "    f.endswith(\"\\n\")\n",
    "    return f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq=dict()\n",
    "leng=387"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def çıkar(i):\n",
    "    c=i\n",
    "    ada=metinoku(i)\n",
    "    txt=open(ada,\"r\")\n",
    "    f=txt.read()\n",
    "    tokenize_sent = sent_tokenize(f) \n",
    "    for i in range(0,len(tokenize_sent)):\n",
    "        tokenize_sent[i]=re.sub(r'[^\\w\\s]','',tokenize_sent[i])\n",
    "        \n",
    "    adj_matrix= np.zeros((len(tokenize_sent),len(tokenize_sent))) #Cümle sayısına göre \n",
    "    sent_rank = np.random.rand(len(tokenize_sent)) #Cümle değerleri için tuttuğum değişken\n",
    "\n",
    "#Stopword'lerin kaldırılması\n",
    "    stop = stopwords.words('english')\n",
    "    process_sent=list()\n",
    "    \n",
    "    for i in range(0,len(tokenize_sent)):\n",
    "        if i not in stop:\n",
    "            process_sent.append(tokenize_sent[i].split())\n",
    "    freq=dict()\n",
    "    copy_sent=process_sent\n",
    "    ps= PorterStemmer()\n",
    "    for sentence_in_running,i in enumerate(process_sent):\n",
    "        for word_in_running,j in enumerate(i):\n",
    "            copy_sent[sentence_in_running][word_in_running]=ps.stem(j)\n",
    "            \n",
    "    for sentence in copy_sent:\n",
    "        a=len(sentence)\n",
    "        for word in sentence:\n",
    "            if word in freq:\n",
    "                freq[word]=freq[word]+1\n",
    "                freq[word]=freq[word]/a\n",
    "            else :\n",
    "                freq[word]=1\n",
    "                freq[word]/a\n",
    "    idfdata=dict()\n",
    "    def find_idf(a):\n",
    "        for sentence in copy_sent:\n",
    "            for word in sentence:\n",
    "                if a==word:\n",
    "                    idfdata[a]=idfdata[a]+1\n",
    "            pass\n",
    "\n",
    "    for sentence in copy_sent:\n",
    "        for word in sentence:\n",
    "            idfdata[word]=0\n",
    "            find_idf(word)\n",
    "            \n",
    "    a=len(sentence)        \n",
    "    idfdeger=dict()\n",
    "    for key in idfdata:\n",
    "        idfdeger[key]=math.log(a/idfdata[key])\n",
    "    \n",
    "    for sentence in copy_sent:\n",
    "        for word in sentence:\n",
    "            freq[word]=(freq[word]*idfdeger[word])        \n",
    "    def cosinus(a,b):\n",
    "        value=[a,b]\n",
    "        count_vectorizer = CountVectorizer()\n",
    "        sparse_matrix = count_vectorizer.fit_transform(value)\n",
    "        doc_term_matrix = sparse_matrix.todense()\n",
    "        df = pd.DataFrame(doc_term_matrix,\n",
    "                  columns=count_vectorizer.get_feature_names(), \n",
    "                  index= [value])\n",
    "    #print(df.head())\n",
    "        cos = cosine_similarity(df, df)\n",
    "        cos2=cos[0][1]\n",
    "    #print(cosDf.head())\n",
    "        return cos2\n",
    "    \n",
    "    for i in range(0,len(tokenize_sent)):\n",
    "        for j in range(i+1,len(tokenize_sent)):\n",
    "            adj_matrix[i,j] = adj_matrix[j,i] = cosinus(tokenize_sent[i],tokenize_sent[j])\n",
    "    cümleler={}\n",
    "    for i in range(len(copy_sent)):\n",
    "        cümleler[i]=0\n",
    "    \n",
    "    for i in range(0, len(copy_sent)):\n",
    "        for j in range(0,len(copy_sent[i])):\n",
    "            cümleler[i]=cümleler[i]+freq[copy_sent[i][j]]\n",
    "    \n",
    "    def calculate_weight(sent_rank,adjacency,shp,cümleler):\n",
    "        sent_rank = np.array(sent_rank)\n",
    "        for node1 in range(0,shp[0]):\n",
    "            sent_rank[node1] = 0\n",
    "            for node2 in range(0,shp[0]):\n",
    "                sent_rank[node1] = (adj_matrix[node1,node2]*cümleler[node1])**2+sent_rank[node1]\n",
    "            \n",
    "        return sent_rank\n",
    "    sent_rank = calculate_weight(sent_rank,adj_matrix,adj_matrix.shape,cümleler)\n",
    "    sentences_rank=(sent_rank).argsort()\n",
    "    \n",
    "    summarization_sorted=np.sort(sentences_rank[1:7])\n",
    "    \n",
    "    system_sum=\"\"\n",
    "    for i in range(0,len(summarization_sorted)):\n",
    "        system_sum=system_sum+tokenize_sent[summarization_sorted[i]]+\".\"\n",
    "\n",
    "    hyp=system_sum\n",
    "    \n",
    "    ref=özetal(c)\n",
    "    rouge=Rouge()\n",
    "    scores = rouge.get_scores(hyp, ref,avg=True)\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "rouge_1_f=0\n",
    "rouge_1_p=0\n",
    "rouge_1_r=0\n",
    "rouge_2_f=0\n",
    "rouge_2_p=0\n",
    "rouge_2_r=0\n",
    "rouge_l_f=0\n",
    "rouge_l_p=0\n",
    "rouge_l_r=0\n",
    "for x in range(1,leng):\n",
    "    scores=çıkar(x)\n",
    "    rouge_1_f=scores['rouge-1']['f']+rouge_1_f\n",
    "    rouge_1_p=scores['rouge-1']['p']+rouge_1_p\n",
    "    rouge_1_r=scores['rouge-1']['r']+rouge_1_r\n",
    "    rouge_2_f=scores['rouge-2']['f']+rouge_2_f\n",
    "    rouge_2_p=scores['rouge-2']['p']+rouge_2_p\n",
    "    rouge_2_r=scores['rouge-2']['r']+rouge_2_r\n",
    "    rouge_l_f=scores['rouge-l']['f']+rouge_l_f\n",
    "    rouge_l_p=scores['rouge-l']['p']+rouge_l_p\n",
    "    rouge_l_r=scores['rouge-l']['r']+rouge_l_r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4602194811921654"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rouge_1_f/leng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3183550305228785"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rouge_2_f/leng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4604316568330196"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rouge_l_f/leng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " idfdata=dict()\n",
    "    def find_idf(a):\n",
    "        for sentence in copy_sent:\n",
    "            for word in sentence:\n",
    "                if a==word:\n",
    "                    idfdata[a]=idfdata[a]+1\n",
    "            pass\n",
    "\n",
    "    for sentence in copy_sent:\n",
    "        for word in sentence:\n",
    "            idfdata[word]=0\n",
    "            find_idf(word)\n",
    "            \n",
    "    a=len(sentence)        \n",
    "    idfdeger=dict()\n",
    "    for key in idfdata:\n",
    "        idfdeger[key]=math.log(a/idfdata[key])\n",
    "    \n",
    "    for sentence in copy_sent:\n",
    "        for word in sentence:\n",
    "            freq[word]=(freq[word]*idfdeger[word])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
